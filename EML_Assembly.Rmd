---
title: "EML Assembly for NES-LTER Small Pelagic Fish Diet and Stable Isotope Data from 2013-2015"
author: "Jaxine Wolfe"
date: "09/24/2019"
output: html_document
---

## Data Cleaning 

This section of code will read in the raw excel file, convert the data from wide to long format, fix problematic column headers, add useful columns, and write the file as a CSV. 

The instructions for installing EMLassemblyline package can be found [here](https://github.com/EDIorg/EMLassemblyline/blob/master/documentation/instructions.md). This documentation also includes instructions for assembling EML templates for export. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

# Load other necessary libraries
library(tidyverse)
library(readxl)
library(lubridate)

# For EML
# Install devtools
# install.packages("devtools")
# Load devtools
library(devtools)

# Install and load EMLassemblyline
# install_github("EDIorg/EMLassemblyline")
library(EMLassemblyline)
# load EML
library(EML)

# clear workspace for local development
rm(list = ls())

# assign resused directory to a variable
dir <- "/Users/jaxinewolfe/Documents/WHOI/NESLTER/nes-lter-fish-diet-isotope"
# set working directory
setwd(dir)

```

## Combining Spring and Fall NOAA Fisheries Cruise Datasets

This information will be used to supplement the diet and stable isotope datasets with geospatial and temporal data.

For the Fisheries trawl datasets, the spring bottom trawl survey data can be found [here](ftp://ftp.nefsc.noaa.gov/pub/dropoff/PARR/PEMAD/ESB/22561), and the fall [here](ftp://ftp.nefsc.noaa.gov/pub/dropoff/PARR/PEMAD/ESB/22560). Only the SVSTA tables are used. 

Note date of access.
```{r}
# set the path to the fisheries directory
fisheries_dir <- "/Users/jaxinewolfe/Documents/Research/PEP/NESLTER/Data/LlopizLab/CCA/FSCSTables_SVSTA/"
# create list of files in the working directory
file_list <- list.files(path = fisheries_dir, full.names = TRUE)

# Define columns to be extracted from fisheries data
FSCScols <- c("CRUISE6", "STATION", "GMT_YEAR", "GMT_MONTH", "GMT_DAY", "GMT_TIME", 
              "DECDEG_BEGLAT", "DECDEG_BEGLON", "AVGDEPTH")

# Combine spring and fall cruise datasets to be merged with the diet data
for (i in 2:length(file_list)){
  # read the first file in the fisheries directory
  FSCSdataset <- read_csv(file_list[1]) %>%
    select(FSCScols) %>%
    filter(GMT_YEAR >= 2013 & GMT_YEAR <= 2015)
  # create temporary dataset to ammend the FSCSdataset
  temp_dataset <- read_csv(file_list[i]) %>% select(FSCScols)
  # add the rows of the new dataset (colnames should be the same)
  FSCSdataset <- rbind(FSCSdataset, temp_dataset[, colnames(FSCSdataset)])
  FSCSdataset[is.na(FSCSdataset)] <- "NA" # convert empties to NA
  # discard temporary dataset
  rm(temp_dataset)
}

# Consolodate GMT year, month, day columns into one
FSCSdataset$date <- with(FSCSdataset,
                               ymd(paste(GMT_YEAR, GMT_MONTH, GMT_DAY, sep= ' '),
                                       tz = "GMT"))

# remove columns used to consolo-date heh
FSCSdataset <- FSCSdataset %>% select(-GMT_YEAR, -GMT_MONTH, -GMT_DAY)

```

## Preparing Diet Data for EDI

Steps:
• convert original dataframe from wide to long (gathering prey columns into one)
• merge temporal columns from fisheries datasets and consolodate these into a GMT date and time column
• add column with unique identifier for each observation
• define the Time column as time_local and convert to %H:%M:%S format
• add columns specifying resolved scientific name and taxonomic serial number from ITIS
• eliminate unnecessary columns and rename other columns as needed

Include Llopiz_resolved.csv on GitHub and refer to tag for final revision of ITISverification.Rmd

```{r}

# set filename to variable
diet_xls <- "Forage_Fish_Diet_Data_2013_2015_Final.xlsx"

# Load stomach content data from excel sheet
diet <- read_excel(path = paste0(dir, "/fish-diet/", diet_xls), 
                  sheet = 1, na = "NA")
# check for duplicate rows
diet_unique <- unique(diet)
# filter(n() < 1)
# There is one duplicated row in the data
diet <- diet_unique

# GENERALIZE THIS STEP
# Problem: "S. scombrus" and "S. Scombrus" both exist in the dataset
# standardize the naming scheme
diet$Species[diet$Species == "S. Scombrus"] <- "S. scombrus"
# unique(diet_join$Species) # check unique fish species

# add column with unique identifier for each observation
diet$uniqueIdentifierFish <- with(diet,
                         paste(Cruise, Station, FishNum, sub(". ", "_", Species), 
                               sep = "_"))

# look at the spreadsheet layout, data is in wide format
# str(diet)

# define prey columns
preycols <- c("Centropages spp.", "Calanus spp.","PPC", "Temora longicornis",
              "Calanoida", "Candacia spp.", "Caligus spp.", "Hyperiidea", "Phronimidae",
              "Hyperia spp.", "Parathemisto spp.", "Pronoidae", "Lycaenidae", "Mysidae",
              "Mysis mixta", "Mysis bigelowi", "Neomysis spp.", "Oikopleura spp.", 
              "Limacina helicina", "Clione limacina", "Euphausiacea", "Euphausia spp.",
              "Meganyctiphanes norvegica", "Thysanopoda spp.", "Thysanoessa spp.", "Gammarus spp.",
              "Ampithoidae", "Gammaria spp.", "Haustoriidae", "Corophiidae", "Liljeborgiidae",
              "Meltidae", "Aoridae", "Chaetognatha", "Ostracoda", "Crustacean_Larvae",
              "Cladocera", "Ammodytes spp.", "Larval_Fish", "Fish_Remains", "Polychaeta",
              "Cumacea", "Isopoda", "Other", "Unknown", "Nematoscelis spp.")

# isolate fishes with empty guts
diet_empty <- diet %>%
  mutate(preytotal = select(., preycols) %>% rowSums(na.rm = TRUE)) %>%
  filter(preytotal == 0) %>% # isolate rowsums of zero
  select(-preytotal) %>%
  gather(preyTaxon, preyCount, preycols, factor_key = TRUE)
diet_empty$preyTaxon <- as.character(-9999) # convert prey taxon to 'missing'
diet_empty[is.na(diet_empty)] <- 0 # convert NA preycounts to 0
# isolate rows of unique fish
diet_empty <- unique(diet_empty)

# convert data to long format
diet_long <- diet %>%
  gather(preyTaxon, preyCount, preycols, factor_key = TRUE) %>%
  filter(preyCount != "0") # filter out counts of zero
# add rows of fish with empty guts
diet_long <- rbind(diet_long, diet_empty)

## Merge Info from Fisheries Data --------
# Add fisheries geospatial info to diet data
# Merge diet and fisheries datasets based on cruise and station
# use unique to remove duplicate rows
diet_join <- left_join(x = diet_long, y = FSCSdataset, 
                       by = c("Cruise" = "CRUISE6", "Station" = "STATION"))

# Convert the Time column to %H:%M:%S format in the diet dataset
diet_join$time_local <- format(as.POSIXct(str_pad(diet_join$Time, 4, pad = "0"),
                                   format="%H%M", origin = ""), "%H:%M:%S")

## Adding Scientific Names ----------
# Prey
# load the ITIS_Validation.Rmd output
itis_resolved <- read_csv("Llopiz_resolved.csv") %>%
  select(Llopiz_preytypes, resolved_names, resolved_id_fromgnr) # select columns from dataset

# standardize the formatting of the preytype column
diet_join$preytype_stnd <- trimws(gsub('([[:upper:]])', ' \\1',
                                diet_join$preyTaxon))
  
# merge diet data with ITIS resolved names
diet_resolved <- left_join(x = diet_join, y = itis_resolved,
                            by=(c("preytype_stnd"="Llopiz_preytypes")))

# assign missing values for empty fish guts
# loop through rows 
for (i in 1:nrow(diet_resolved)) {
  if (diet_resolved$preyCount[i] == 0) {
    diet_resolved$preyTaxon[i] <- as.character(-9999)
    diet_resolved$resolved_names[i] <- as.character(-9999)
    diet_resolved$resolved_id_fromgnr[i] <- as.character(-9999)
    }
}

# Fish
# Load stomach content data from excel sheet
fishkey <- read_csv(paste0(dir, "/fish-lookup.csv"))
# merge diet data with fish key
diet_final <- left_join(x = diet_resolved, y = fishkey,
                            by=(c("Species"="abbrevName_fish")))

## Quality Assurance ----------

# reassign dataset 
diet_check <- diet_final

# create empty columns to check mismatches
diet_check$lon_match <- FALSE
diet_check$lat_match <- FALSE
diet_check$depth_match <- FALSE

# loop through each row 
for (i in 1:nrow(diet_check)) {
  # if there's no fisheries data, move to the next row
    if (is.na(diet_check$date[i]) == TRUE) {
      diet_check$lon_match[i] <- NA_character_
      diet_check$lat_match[i] <- NA_character_
      diet_check$depth_match[i] <- NA_character_
      i <- i + 1
    next
    }
    # check if Fisheries and Justins average depths match
    if (diet_check$Station_Depth[i] == as.numeric(diet_check$AVGDEPTH[i])) {
      # set name_match to true
      diet_check$depth_match[i] <- TRUE
    }
      # check if Fisheries and Justin's coordinates match
      if (round(diet_check$Longitude[i], 1) == round(diet_check$DECDEG_BEGLON[i], 1)) {
      # set name_match to true
      diet_check$lon_match[i] <- TRUE
    }
      if (round(diet_check$Latitude[i], 1) == round(diet_check$DECDEG_BEGLAT[i], 1)) {
      # set name_match to true
      diet_check$lat_match[i] <- TRUE
    }
}

# use 'ifelse' to add longitude flag column to diet dataset 
diet_check$decimalLongitude_flag <- ifelse(diet_check$lon_match == FALSE, yes = 3, no = 1)

# isolate the rows that are FALSE
coord_mismatch <- diet_check %>% filter(lon_match == FALSE | lat_match == FALSE)
depth_mismatch <- diet_check %>% filter(depth_match == FALSE)

# write csv files
# write.csv(coord_mismatch, paste0(dir, "/fish-diet/coord_mismatch.csv"), row.names = FALSE)
# write.csv(depth_mismatch, paste0(dir, "/fish-diet/depth_mismatch.csv"), row.names = FALSE)

## Final Adjustments --------

# assign final dataframe, leaving out unnecessary columns
diet_EDI <- diet_check %>%
  select(-Time, -DECDEG_BEGLAT, -DECDEG_BEGLON, -AVGDEPTH, 
         -preytype_stnd, -lon_match, -lat_match, -depth_match)
  
# Rename columns as needed
# load in column key
columnkey <- read_csv("column-lookup.csv")

# create function to loop through the column headers
column_rename <- function(x, key) {
  for (i in 1:length(names(x))) {
  colname <- names(x)[i]
  # if the column name doesn't match anything, don't rename it
  if (is.na(match(colname, key$old)) == TRUE) {
      i <- i + 1
    next
  }
  # otherwise replace the old column name with the new
  colnames(x)[colnames(x) == colname] <- key$new[match(colname, key$old)]
  }
  return(x)
}

# employ renaming function
diet_EDI <- column_rename(x = diet_EDI, key = columnkey)

# reorder columns
diet_EDI <- diet_EDI[,c("cruise", "station", "cruise_station", "decimalLatitude", "decimalLongitude", "decimalLongitude_flag", "time_UTC", "time_local", "date", "region", "average_depth", "FishNum",  "forkLength", "abbrevName_fish", "uniqueIdentifierFish", "scientificName_fish", "scientificNameID_fish", "vernacularName", "preyTaxon", "scientificName_preyTaxon", "scientificNameID_preyTaxon", "preyCount")]

# write the CSV file for upload to the EDI repository
write.csv(diet_EDI, paste0(dir, "/fish-diet/nes-lter-fish-diet-2013-2015.csv"),
          row.names = FALSE)

```
The Quality Assurance section investigates the differences between the Fisheries datasets and Justin's provided dataset. The coordinate (only longitude) conflicts occurred for cruises 201402 and 201504, and the conflicts of depth only occur for cruise 201504.

## Quality Assurance: Frequency check

Check that the frequency of occurence and total counts of prey taxa per fish species aligned with the frequencies reported in Suca et al. (2018) Supplementary Material.
```{r}

## Frequency of Occurence
# diet_occur <- diet_EDI %>%
#   filter(vernacularName == "Atlantic mackerel") %>%
#   select(vernacularName, preyTaxon) %>%
#   group_by(vernacularName, preyTaxon) %>%
#   # tally the occurrance of prey taxon for give fish species 
#   add_tally(name = "preyOccurance") %>%
#   # divide the occurances by the total number of fish containing prey items
#   mutate(preyFreq = (preyOccurance/nrow(diet_EDI %>% 
#                                   filter(vernacularName == "Atlantic mackerel")))*100)
# diet_occur <- unique(diet_occur)
# # write.csv(diet_occur, paste0(dir,"/fish-diet/FreqOfOccurance.csv"), 
# #           row.names = FALSE)
# # pull out example
# # diet_occur %>% filter(preyTaxon == "Ostracoda")
# 
# ## Prey totals across fish species
# diet_totals <- diet_EDI %>%
#   select(vernacularName, preyCount) %>%
#   group_by(vernacularName) %>%
#   summarise(preytotal = sum(preyCount))
# manually checked against input file

## Using the original wide-format data

# Check against the prey totals listed in the supplementary data
# Turn this into a function, opts to enter species and prey taxon
freq_occur <- diet %>%
  select(Species, Euphausiacea) %>%
  filter(Species == "A. pseudoharengus") %>%
  filter(Euphausiacea != "0") %>% # filter out counts of zero
  # tally the occurrance of prey taxon for give fish species 
  add_tally(name = "preyOccurance") %>%
  # divide the occurances by the total number of fish containing prey items
  mutate(preyFreq = (preyOccurance/nrow(diet %>% 
                                  filter(Species == "A. pseudoharengus")))*100)

# Determine number of unique fish identifiers per fish species 
fish <- fishkey$abbrevName_fish

for (i in 1:length(fish)) {
  fish_tally <- diet_EDI %>%
  filter(abbrevName_fish == fish[i]) %>%
  select(uniqueIdentifierFish) %>%
  # tally the occurrance of fish species
  add_tally(name = "tally") 
  
print(paste0("Unique observations for ", fish[i], ": ", nrow(unique(fish_tally))))
}
# we lost unique fish in the conversion from wide to long
# UPDATE: code modified to retain unique fish with empty guts
```

## Mapping the Data

This chunk of code enables a visual map check of the data points. For the diet dataset, we would expect that none of the data points are beyond the shelf or inland. The geospatial and temporal fields within the stable isotope data were pulled from the fisheries logs. 
```{r}
library(maps)
library(dplyr)

nes <- map_data("state") %>% filter(long > -77)

# Justin's given coordinates
ggplot() +
  geom_polygon(data = nes, mapping = aes(x = long, y = lat, group = group),
               fill = NA, color = "grey50") +
  geom_point(diet_final, mapping = aes(x = Longitude, y = Latitude, color = Region),
            size = 1) + 
  coord_fixed(1.3) +
  theme_classic()

# Fisheries given coordinates
ggplot() +
  geom_polygon(data = nes, mapping = aes(x = long, y = lat, group = group),
               fill = NA, color = "grey50") +
  geom_point(diet_final, mapping = aes(x = DECDEG_BEGLON, y = DECDEG_BEGLAT, color = Region),
            size = 1) + 
  coord_fixed(1.3) +
  theme_classic()

```
The data provided by Justin contains errors in the longitude. We have investigated these occurances and included a flag column for the longitude.


## Construct XML for Diet Data

NOTE: Most templates had to be manually annotated after they were imported. Information from the excel spreadsheet workbook was copy-pasted into the .txt files.

The overview of EML can  be found [here](https://github.com/ropensci/EML). 
At the moment, EML assembly line doesn't provide project abstract or publisher.
```{r}

## ASSEMBLE TEMPLATES ----------
# save filename in variable
diet_csv <- "nes-lter-fish-diet-2013-2015.csv"

# Import EDI templates for diet dataset licensed under CCBY
# import_templates(path = paste0(dir,"/fish-diet"),
#                  license = "CCBY",
#                  data.files = diet_csv)
                   
# import categorical variable template for diet data
# define_catvars(path = paste0(dir,"/fish-diet"))
# Region is the only catvar, defined manually within the template
          
# View and search the standard units dictionary
# view_unit_dictionary()

# Determine temporal coverage for make_eml
# define start and end date (YYYY-MM-DD)
startdate <- min(diet_EDI$date, na.rm = TRUE)
enddate <- max(diet_EDI$date, na.rm = TRUE)
# temporal.coverage expects objects of 'character' class
startdate_as_char <- as.character(startdate)
enddate_as_char <- as.character(enddate)

# Determine geographic coverage for make_eml
# round to 5 decimal places
North <- round(max(diet_EDI$decimalLatitude, na.rm = TRUE), 5)
East <- round(max(diet_EDI$decimalLongitude, na.rm = TRUE), 5)
South <- round(min(diet_EDI$decimalLatitude, na.rm = TRUE), 5)
West <- round(min(diet_EDI$decimalLongitude, na.rm = TRUE), 5)

# MAKE EML -----------
# for data and metadata templates co-located at path
make_eml(path = paste0(dir,"/fish-diet"),
         data.path = paste0(dir,"/fish-diet"),
         dataset.title = "Diet Composition for Small Pelagic Fishes across the Northeast U.S. Continental Shelf from 2013-2015",
         # data.path = data_dir,
         data.table = diet_csv,
         data.table.description = "Fish diet data cleaned for EDI",
         other.entity = diet_xls,
         other.entity.description = "Original fish diet dataset from the Llopiz lab",
         temporal.coverage = c(startdate_as_char, enddate_as_char),
         geographic.description = "Northeast U.S. Shelf",
         geographic.coordinates = c(North, East, South, West),
         maintenance.description = "completed", 
         user.id = "NES",
         user.domain = "LTER",
         package.id = "knb-lter-nes.2.2")

```


## Preparing Stable Isotope Data for EDI

Steps:
• add column with unique identifier for each observation
• merge on this column to add GMT date and time columns from the finalized diet dataset, along with the scientific name and TSN for the fish species
• rename columns as needed

```{r}

# set filename to variable
iso_xls <- "Forage_Fish_Stable_Isotope_Data_2013_2015_Final.xlsx"

# Load stomach content data from excel sheet
isotope <- read_excel(path = paste0(dir, "/fish-isotope/", iso_xls),
                      sheet = "DataTable", na = "NA")
# str(isotope)
# data is already in long format

# add column with unique identifier for each observation
isotope$uniqueIdentifierFish <- with(isotope,
                         paste(Cruise, Station, Fish_Num, sub(". ", "_", Species), 
                               sep = "_"))

# merge fisheries columns (geospatial, temporal, depth info)
iso_join <- unique(left_join(x = isotope, y = FSCSdataset, 
                       by = c("Cruise" = "CRUISE6", "Station" = "STATION")))
iso_join$AVGDEPTH <- as.numeric(iso_join$AVGDEPTH)
# merge fishkey columns
iso_fish <- left_join(x = iso_join, y = fishkey,
                            by=(c("Species"="abbrevName_fish")))

## Final Adjustments --------

# employ renaming function to rename columns as needed
isotope_EDI <- column_rename(x = iso_fish, key = columnkey)

# reorder columns
isotope_EDI <- isotope_EDI[,c("cruise", "station", "decimalLatitude", "decimalLongitude", "time_UTC", "date", "average_depth", "Fish_Num", "abbrevName_fish", "uniqueIdentifierFish", "scientificName_fish", "scientificNameID_fish", "vernacularName", "d13C", "d15N", "C_to_N", "d13C_corr")]

# write the CSV file to new directory
# this will be the dataset published to the EDI repository
write.csv(isotope_EDI, paste0(dir, "/fish-isotope/nes-lter-fish-stable-isotope-2013-2015.csv"), 
          row.names = FALSE)

```

## Quality Assurance: Statistical check

This chunk will inspect the isotope data to make sure it aligns statistically with the expected mean and standard deviation.
```{r}

# compute summary stats
iso_check <- isotope_EDI %>%
  select(d13C, d15N, C_to_N, d13C_corr) %>%
  summarise(mean_d13C = mean(d13C),
            mean_d15N = mean(d15N),
            mean_C_to_N = mean(C_to_N),
            mean_d13C_corr = mean(d13C_corr),
            min_d13C = min(d13C),
            min_d15N = min(d15N),
            min_C_to_N = min(C_to_N),
            min_d13C_corr = min(d13C_corr))

```

## Construct XML for Stable Isotope Data

NOTE: Most templates had to be manually annotated after they were imported. Information from the excel spreadsheet workbook was copy-pasted into the .txt files.

The overview of EML can  be found [here](https://github.com/ropensci/EML). 
At the moment, EML assembly line doesn't provide project abstract or publisher. 
```{r}

# save filename to variable
iso_csv <- "nes-lter-fish-stable-isotope-2013-2015.csv"

## ASSEMBLE TEMPLATES ----------
# Import EDI templates for diet dataset licensed under CCBY
# import_templates(path = paste0(dir, "/fish-isotope"),
#                  license = "CCBY",
#                  data.files = iso_csv)
# no categorical variables for this data
                              
# Determine temporal coverage for make_eml
# define start and end date (YYYY-MM-DD)
startdate <- min(isotope_EDI$date, na.rm = TRUE)
enddate <- max(isotope_EDI$date, na.rm = TRUE)
# temporal.coverage expects objects of 'character' class
startdate_as_char <- as.character(startdate)
enddate_as_char <- as.character(enddate)

# Determine geographic coverage for make_eml
# round to 5 decimal places
North <- round(max(isotope_EDI$decimalLatitude, na.rm = TRUE), digits = 5)
East <- round(max(isotope_EDI$decimalLongitude, na.rm = TRUE), digits = 5)
South <- round(min(isotope_EDI$decimalLatitude, na.rm = TRUE), digits = 5)
West <- round(min(isotope_EDI$decimalLongitude, na.rm = TRUE), digits = 5)

# MAKE EML -------------
# for data and metadata templates co-located at path
make_eml(path = paste0(dir,"/fish-isotope"),
         data.path = paste0(dir,"/fish-isotope"),
         dataset.title = "Stable Isotope Data for Small Pelagic Fishes across the Northeast U.S. Continental Shelf from 2013-2015",
         # data.path = data_dir,
         data.table = iso_csv,
         data.table.description = "Fish stable isotope dataset cleaned for EDI",
         other.entity = iso_xls,
         other.entity.description = "Original fish stable isotope datasheet from the Llopiz lab",
         temporal.coverage = c(startdate_as_char, enddate_as_char),
         geographic.description = "Northeast U.S. Shelf",
         geographic.coordinates = c(North, East, South, West),
         maintenance.description = "completed", 
         user.id = "NES",
         user.domain = "LTER",
         package.id = "knb-lter-nes.3.1")

```

## Insert Custom Project Node

ANY CHANGES TO THE XML FILE MUST BE PUSHED TO GITHUB BEFORE RUNNING THIS CHUNK

Step 1: Read in the xml file and the new xml node
Step 2: Insert the new node or replace the old node with the new node
Step 3: Write the modified xml file 

Instructions for node replacement using the xml2 package can be found [here](https://cran.r-project.org/web/packages/xml2/vignettes/modification.html).

```{r}
# install.packages("xml2")
library(xml2)

# read in project node
project_eml <- read_xml("parent_project.txt", from = "xml")

# read in xml files exported by make_eml
# diet data
diet_eml <- read_xml("https://raw.githubusercontent.com/WHOIGit/nes-lter-fish-diet-isotope/master/fish-diet/knb-lter-nes.2.2.xml", from  = "xml")
# isotope data
iso_eml <- read_xml("https://raw.githubusercontent.com/WHOIGit/nes-lter-fish-diet-isotope/master/fish-isotope/knb-lter-nes.3.1.xml", from  = "xml")
# all objects should be of class c("xml_document" "xml_node")

# Function to replace an existant node with a new node in an xml document
node_replacement <- function(x, newnode) {
  # find old project node
  oldnode <- xml_find_first(x, ".//project") # find project node
  # replace with new project node
  xml_replace(oldnode, newnode)
  return(x)
}

# Function to insert a new node into an xml document
node_insert <- function(x, newnode) {
  # find methods node
  methodsnode <- xml_find_first(x, ".//methods")
  # add project node after methods and before dataTable
  xml_add_sibling(methodsnode, newnode, where = "after")
  return(x)
}

# make the neccessary modifications
diet_eml_final <- node_insert(diet_eml, project_eml)
iso_eml_final <- node_insert(iso_eml, project_eml)

# check nodes
xml_children(xml_children(diet_eml_final)[[2]])
xml_children(xml_children(iso_eml_final)[[2]])

# check that the file is still valid
eml_validate(diet_eml)
eml_validate(iso_eml)

# write modified xml file
# write_xml(diet_eml_final, paste0(dir, "/fish-diet/knb-lter-nes.2.2.xml"))
# write_xml(iso_eml_final, paste0(dir, "/fish-isotope/knb-lter-nes.3.1.xml"))

```

